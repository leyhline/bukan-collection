{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will do mostly the same as the `07-pipeline` but use some tricks to speed things up like multiprocessing as well as making sure memory does not overflow by processing the data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "import os\n",
    "from enum import Enum\n",
    "from glob import glob\n",
    "import logging\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import repeat\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"08-pipeline-multiprocessing.log\", level=logging.INFO,\n",
    "                    format=\"%(asctime)s %(levelname)-8s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_string = \"mysql://bukanuser@localhost/bukan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    \"\"\"From <https://github.com/kuk/log-progress>\"\"\"\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = pd.read_csv(\"bukan-overview-final.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I need to do now per image is:\n",
    "\n",
    "1. Read, greyscale and crop all images\n",
    "2. Split right/left page if necessary\n",
    "3. Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page(Enum):\n",
    "    \"\"\"Japanese reading order is from right to left.\"\"\"\n",
    "    whole = 0\n",
    "    right = 1\n",
    "    left  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img):\n",
    "    target_height = 660\n",
    "    target_width = 990\n",
    "    height, width = img.shape\n",
    "    x1 = (width - target_width) // 2\n",
    "    y1 = (height - target_height) // 2\n",
    "    x2 = x1 + target_width\n",
    "    y2 = y1 + target_height\n",
    "    return img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv.imread(path, flags=cv.IMREAD_REDUCED_GRAYSCALE_4)\n",
    "    img = crop_image(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(img):\n",
    "    height, width = img.shape\n",
    "    assert width == 990\n",
    "    half_width = width // 2\n",
    "    return img[:, :half_width], img[:, half_width:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_nr_from_path(path):\n",
    "    return int(path[-9:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(image: np.ndarray, book_id: int, page_nr: int, page_enum: Page):\n",
    "    path = f\"output/images/{book_id}/{book_id}_{page_nr:0>5}_{page_enum.value}.jpg\"\n",
    "    assert cv.imwrite(path, image, [cv.IMWRITE_JPEG_QUALITY, 80, cv.IMWRITE_JPEG_OPTIMIZE, True])\n",
    "    logging.info(f\"Image written: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptors_to_dataframe(descriptors: np.ndarray, book_id: int, page_nr: int, page_enum: Page):\n",
    "    df = pd.DataFrame(descriptors)\n",
    "    df.index = pd.MultiIndex.from_product([[book_id], [page_nr], [page_enum.value], df.index],\n",
    "                                          names=[\"book\", \"page\", \"lr\", \"feature\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints_to_dataframe(keypoints: List[cv.KeyPoint], book_id: int, page_nr: int, page_enum: Page):\n",
    "    df = pd.DataFrame([(kp.pt[0], kp.pt[1], kp.size, kp.angle, kp.response, kp.octave, kp.class_id) for kp in keypoints],\n",
    "                      columns=[\"x\", \"y\", \"size\", \"angle\", \"response\", \"octave\", \"class_id\"])\n",
    "    df.index = pd.MultiIndex.from_product([[book_id], [page_nr], [page_enum.value], df.index],\n",
    "                                          names=[\"book\", \"page\", \"lr\", \"feature\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(image: np.ndarray, book_id: int, page_nr: int, page_enum: Page,\n",
    "                    engine: sqlalchemy.engine.Engine, detector: cv.Feature2D):\n",
    "    keypoints, descriptors = detector.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        logging.warning(f\"No features detected for: {book_id}/{page_nr}/{page_enum.name}\")\n",
    "        return\n",
    "    descriptors = descriptors_to_dataframe(descriptors, book_id, page_nr, page_enum)\n",
    "    descriptors.to_sql(\"descriptor\", engine, if_exists=\"append\")\n",
    "    logging.info(f\"Descriptors written to database for: {book_id}/{page_nr}/{page_enum.name}\")\n",
    "    keypoints = keypoints_to_dataframe(keypoints, book_id, page_nr, page_enum)\n",
    "    keypoints.to_sql(\"keypoint\", engine, if_exists=\"append\")\n",
    "    logging.info(f\"Keypoints written to database for: {book_id}/{page_nr}/{page_enum.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(path, book_id: int, nr_pages_per_image: int, engine: sqlalchemy.engine.Engine,\n",
    "                 detector: cv.Feature2D):\n",
    "    page_nr = extract_page_nr_from_path(path)\n",
    "    image = read_image(path)\n",
    "    if nr_pages_per_image == 1:\n",
    "        write_image(image, book_id, page_nr, Page.whole)\n",
    "        detect_features(image, book_id, page_nr, Page.whole, engine, detector)\n",
    "    elif nr_pages_per_image == 2:\n",
    "        left_image, right_image = split_image(image)\n",
    "        write_image(right_image, book_id, page_nr, Page.right)\n",
    "        detect_features(right_image, book_id, page_nr, Page.right, engine, detector)\n",
    "        write_image(left_image, book_id, page_nr, Page.left)\n",
    "        detect_features(left_image, book_id, page_nr, Page.left, engine, detector)\n",
    "    else:\n",
    "        logging.warning(f\"Strange number of pages per image for {path}: {nr_pages_per_image} (Skipping)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_images_and_features(overview_df: pd.DataFrame, engine: sqlalchemy.engine.Engine,\n",
    "                                          detector: cv.Feature2D):\n",
    "    try:\n",
    "        for book_id, book_metadata in log_progress(overview_df.iterrows(), every=1, size=len(overview_df), name=\"Rows\"):\n",
    "            os.makedirs(f\"output/images/{str(book_id)}\", exist_ok=True)\n",
    "            nr_images = book_metadata[\"NrImages\"]\n",
    "            nr_pages_per_image = book_metadata[\"NrPages\"]\n",
    "            image_paths = glob(f\"data/{book_id}/image/*.jpg\")\n",
    "            assert len(image_paths) == nr_images\n",
    "            image_paths.sort()\n",
    "            for path in image_paths:\n",
    "                process_path(path, book_id, nr_pages_per_image, engine, detector)\n",
    "    except Exception as e:\n",
    "        logging.critical(str(e))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1863f9cc810e49d690377cd3e0771d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=336)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of this took: 10390.628847228014 seconds.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(engine_string)\n",
    "akaze = cv.AKAZE_create(cv.AKAZE_DESCRIPTOR_MLDB_UPRIGHT, descriptor_size=0, threshold=0.005)\n",
    "start_time = time.monotonic()\n",
    "save_preprocessed_images_and_features(remaining, engine, akaze)\n",
    "stop_time = time.monotonic()\n",
    "engine.dispose()\n",
    "print(\"All of this took:\", stop_time - start_time, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Feature Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to get all all book combinations as well as a fixed page offset. For each combination I need to run the full pipeline:\n",
    "\n",
    "1. Find matching features\n",
    "2. Filter features by their position\n",
    "3. Compute the homography\n",
    "4. Select features using the homography mask\n",
    "4. **Don't threshold the features by their count**\n",
    "5. Save them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>公開時期</th>\n",
       "      <th>オープンデータ分類</th>\n",
       "      <th>書名（統一書名）</th>\n",
       "      <th>TitleHiragana</th>\n",
       "      <th>TitleRomanji</th>\n",
       "      <th>刊・写</th>\n",
       "      <th>原本請求記号</th>\n",
       "      <th>刊年・書写年</th>\n",
       "      <th>（西暦）</th>\n",
       "      <th>冊数等</th>\n",
       "      <th>(単位)</th>\n",
       "      <th>NrPages</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>NrImages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>国文研書誌ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200018466</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>応仁武鑑</td>\n",
       "      <td>おうにんぶかん</td>\n",
       "      <td>ōninbukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１４９０－７</td>\n",
       "      <td>天保１５</td>\n",
       "      <td>1844</td>\n",
       "      <td>2.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Portrait</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018476</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>応仁武鑑</td>\n",
       "      <td>おうにんぶかん</td>\n",
       "      <td>ōninbukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１４９０－８</td>\n",
       "      <td>弘化３</td>\n",
       "      <td>1846</td>\n",
       "      <td>3.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Portrait</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018713</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>本朝武鑑</td>\n",
       "      <td>ほんちょうぶかん</td>\n",
       "      <td>honchōbukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－５３</td>\n",
       "      <td>［貞享３］</td>\n",
       "      <td>[1686]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018714</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>本朝武鑑</td>\n",
       "      <td>ほんちょうぶかん</td>\n",
       "      <td>honchōbukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－５４</td>\n",
       "      <td>貞享３</td>\n",
       "      <td>1686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018718</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>太平武鑑</td>\n",
       "      <td>たいへいぶかん</td>\n",
       "      <td>taihenbukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－５８</td>\n",
       "      <td>［元禄２］</td>\n",
       "      <td>[1689]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019651</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>御国分武鑑</td>\n",
       "      <td>おくにわけぶかん</td>\n",
       "      <td>okuniwakebukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－３１５</td>\n",
       "      <td>慶応４</td>\n",
       "      <td>1868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019652</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>御国分武鑑</td>\n",
       "      <td>おくにわけぶかん</td>\n",
       "      <td>okuniwakebukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－３１６</td>\n",
       "      <td>慶応４</td>\n",
       "      <td>1868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019661</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>昇栄武鑑</td>\n",
       "      <td>しょうえいぶかん</td>\n",
       "      <td>shōeibukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－３２４</td>\n",
       "      <td>嘉永６</td>\n",
       "      <td>1853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019662</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>昇栄武鑑</td>\n",
       "      <td>しょうえいぶかん</td>\n",
       "      <td>shōeibukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－３２５</td>\n",
       "      <td>安政３</td>\n",
       "      <td>1856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200019666</th>\n",
       "      <td>H29.12</td>\n",
       "      <td>政治・法制</td>\n",
       "      <td>昇栄武鑑</td>\n",
       "      <td>しょうえいぶかん</td>\n",
       "      <td>shōeibukan</td>\n",
       "      <td>刊</td>\n",
       "      <td>ＭＹ－１２０１－３２７</td>\n",
       "      <td>元治１</td>\n",
       "      <td>1864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>冊</td>\n",
       "      <td>2</td>\n",
       "      <td>Landscape</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             公開時期 オープンデータ分類 書名（統一書名） TitleHiragana    TitleRomanji 刊・写  \\\n",
       "国文研書誌ID                                                                  \n",
       "200018466  H29.12     政治・法制     応仁武鑑       おうにんぶかん       ōninbukan   刊   \n",
       "200018476  H29.12     政治・法制     応仁武鑑       おうにんぶかん       ōninbukan   刊   \n",
       "200018713  H29.12     政治・法制     本朝武鑑      ほんちょうぶかん     honchōbukan   刊   \n",
       "200018714  H29.12     政治・法制     本朝武鑑      ほんちょうぶかん     honchōbukan   刊   \n",
       "200018718  H29.12     政治・法制     太平武鑑       たいへいぶかん     taihenbukan   刊   \n",
       "...           ...       ...      ...           ...             ...  ..   \n",
       "200019651  H29.12     政治・法制    御国分武鑑      おくにわけぶかん  okuniwakebukan   刊   \n",
       "200019652  H29.12     政治・法制    御国分武鑑      おくにわけぶかん  okuniwakebukan   刊   \n",
       "200019661  H29.12     政治・法制     昇栄武鑑      しょうえいぶかん      shōeibukan   刊   \n",
       "200019662  H29.12     政治・法制     昇栄武鑑      しょうえいぶかん      shōeibukan   刊   \n",
       "200019666  H29.12     政治・法制     昇栄武鑑      しょうえいぶかん      shōeibukan   刊   \n",
       "\n",
       "                原本請求記号 刊年・書写年    （西暦）  冊数等 (単位)  NrPages     Aspect  NrImages  \n",
       "国文研書誌ID                                                                        \n",
       "200018466    ＭＹ－１４９０－７   天保１５    1844  2.0    冊        2   Portrait        78  \n",
       "200018476    ＭＹ－１４９０－８    弘化３    1846  3.0    冊        2   Portrait       100  \n",
       "200018713   ＭＹ－１２０１－５３  ［貞享３］  [1686]  1.0    冊        2  Landscape        75  \n",
       "200018714   ＭＹ－１２０１－５４    貞享３    1686  1.0    冊        2  Landscape        94  \n",
       "200018718   ＭＹ－１２０１－５８  ［元禄２］  [1689]  1.0    冊        2  Landscape        48  \n",
       "...                ...    ...     ...  ...  ...      ...        ...       ...  \n",
       "200019651  ＭＹ－１２０１－３１５    慶応４    1868  1.0    冊        2  Landscape        28  \n",
       "200019652  ＭＹ－１２０１－３１６    慶応４    1868  1.0    冊        2  Landscape        29  \n",
       "200019661  ＭＹ－１２０１－３２４    嘉永６    1853  1.0    冊        2  Landscape       124  \n",
       "200019662  ＭＹ－１２０１－３２５    安政３    1856  1.0    冊        2  Landscape       125  \n",
       "200019666  ＭＹ－１２０１－３２７    元治１    1864  1.0    冊        2  Landscape       128  \n",
       "\n",
       "[336 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_query(query: str):\n",
    "    engine = create_engine(engine_string)\n",
    "    with engine.connect() as conn:\n",
    "        results = conn.execute(text(query)).fetchall()\n",
    "    engine.dispose()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_books = run_sql_query(\"select book, count(distinct page) from descriptor group by book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(db_books)[1].values <= overview[\"NrImages\"].values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_books) == 336"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
